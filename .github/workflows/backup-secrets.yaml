name: Backup 2FA Secrets (KV)

on:
  schedule:
    # 每天 UTC 04:00 运行（北京时间 12:00）
    - cron: "0 4 * * *"
  workflow_dispatch:
    inputs:
      environment:
        description: "选择备份环境"
        required: true
        default: "production"
        type: choice
        options:
          - production

env:
  BACKUP_RETENTION_DAYS: ${{ secrets.BACKUP_RETENTION_DAYS || 30 }}
  KV_BINDING: "SECRETS_KV"
  KV_KEY: "secrets"

jobs:
  backup-secrets:
    name: Backup 2FA Secrets from KV
    runs-on: ubuntu-latest
    
    steps:
      - name: Check backup backends availability
        id: backends
        env:
          S3_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
          S3_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
          S3_BUCKET: ${{ secrets.S3_BUCKET }}
          S3_REGION: ${{ secrets.S3_REGION }}
          WEBDAV_URL: ${{ secrets.WEBDAV_URL }}
          WEBDAV_USER: ${{ secrets.WEBDAV_USER }}
          WEBDAV_PASSWORD: ${{ secrets.WEBDAV_PASSWORD }}
          GH_BACKUP_TOKEN: ${{ secrets.GH_BACKUP_TOKEN }}
        run: |
          # 检查 S3 后端
          if [[ -n "$S3_ACCESS_KEY_ID" && -n "$S3_SECRET_ACCESS_KEY" && -n "$S3_BUCKET" && -n "$S3_REGION" ]]; then
            echo "S3_ENABLED=true" >> $GITHUB_OUTPUT
            echo "✅ S3 backend: enabled"
          else
            echo "S3_ENABLED=false" >> $GITHUB_OUTPUT
            echo "⚠️ S3 backend: disabled"
          fi
          
          # 检查 WebDAV 后端
          if [[ -n "$WEBDAV_URL" && -n "$WEBDAV_USER" && -n "$WEBDAV_PASSWORD" ]]; then
            echo "WEBDAV_ENABLED=true" >> $GITHUB_OUTPUT
            echo "✅ WebDAV backend: enabled"
          else
            echo "WEBDAV_ENABLED=false" >> $GITHUB_OUTPUT
            echo "⚠️ WebDAV backend: disabled"
          fi

          # 检查 GitHub 后端
          if [[ -n "$GH_BACKUP_TOKEN" ]]; then
            echo "GITHUB_ENABLED=true" >> $GITHUB_OUTPUT
            echo "✅ GitHub backend: enabled"
          else
            echo "GITHUB_ENABLED=false" >> $GITHUB_OUTPUT
            echo "⚠️ GitHub backend: disabled"
          fi

      - name: Get current date
        id: date
        run: echo "date=$(date +'%Y-%m-%d_%H-%M-%S')" >> $GITHUB_OUTPUT

      - name: Install wrangler
        run: npm install -g wrangler

      - name: Export KV Secrets
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: |
          echo "Fetching secrets from KV..."
          npx wrangler kv key get "${{ env.KV_KEY }}" --binding ${{ env.KV_BINDING }} --output=json > backup.json
          
          # 检查是否成功获取数据
          if [ ! -s backup.json ]; then
            echo "❌ Error: Failed to fetch secrets or KV is empty"
            exit 1
          fi
          
          # 压缩备份文件
          gzip backup.json
          echo "✅ Backup compressed: backup.json.gz"

      - name: Encrypt backup (optional)
        env:
          BACKUP_ENCRYPTION_KEY: ${{ secrets.BACKUP_ENCRYPTION_KEY }}
        run: |
          if [ -n "$BACKUP_ENCRYPTION_KEY" ]; then
            echo "Encrypting backup with AES-256..."
            openssl enc -aes-256-cbc -salt -pbkdf2 -iter 100000 \
              -in backup.json.gz \
              -out "2fa_backup_${{ steps.date.outputs.date }}.json.gz.enc" \
              -pass pass:"$BACKUP_ENCRYPTION_KEY"
            rm backup.json.gz
            echo "✅ Backup encrypted"
          else
            echo "⚠️ BACKUP_ENCRYPTION_KEY not set, skipping encryption"
            mv backup.json.gz "2fa_backup_${{ steps.date.outputs.date }}.json.gz"
          fi

      - name: Upload to S3
        if: steps.backends.outputs.S3_ENABLED == 'true'
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ secrets.S3_REGION }}
          BACKUP_ENCRYPTION_KEY: ${{ secrets.BACKUP_ENCRYPTION_KEY }}
        run: |
          ENDPOINT_FLAG=""
          if [ -n "${{ secrets.S3_ENDPOINT }}" ]; then
            ENDPOINT_FLAG="--endpoint-url ${{ secrets.S3_ENDPOINT }}"
          fi

          if [ -n "$BACKUP_ENCRYPTION_KEY" ]; then
            BACKUP_FILE="2fa_backup_${{ steps.date.outputs.date }}.json.gz.enc"
          else
            BACKUP_FILE="2fa_backup_${{ steps.date.outputs.date }}.json.gz"
          fi
          
          aws s3 cp "$BACKUP_FILE" \
            "s3://${{ secrets.S3_BUCKET }}/2fa-backups/" \
            $ENDPOINT_FLAG
          
          echo "✅ Backup uploaded to S3"

      - name: Setup rclone
        if: steps.backends.outputs.WEBDAV_ENABLED == 'true'
        uses: AnimMouse/setup-rclone@v1

      - name: Configure rclone (WebDAV)
        if: steps.backends.outputs.WEBDAV_ENABLED == 'true'
        env:
          WEBDAV_URL: ${{ secrets.WEBDAV_URL }}
          WEBDAV_VENDOR: ${{ secrets.WEBDAV_VENDOR || 'other' }}
          WEBDAV_USER: ${{ secrets.WEBDAV_USER }}
          WEBDAV_PASSWORD: ${{ secrets.WEBDAV_PASSWORD }}
        run: |
          mkdir -p ~/.config/rclone
          RCLONE_WEBDAV_PASS="$(rclone obscure "$WEBDAV_PASSWORD")"

          cat > ~/.config/rclone/rclone.conf <<EOF
          [webdav]
          type = webdav
          url = $WEBDAV_URL
          vendor = $WEBDAV_VENDOR
          user = $WEBDAV_USER
          pass = $RCLONE_WEBDAV_PASS
          EOF

      - name: Upload to WebDAV
        if: steps.backends.outputs.WEBDAV_ENABLED == 'true'
        env:
          BACKUP_ENCRYPTION_KEY: ${{ secrets.BACKUP_ENCRYPTION_KEY }}
          WEBDAV_BASE_PATH: ${{ secrets.WEBDAV_BASE_PATH || '2fa-backups' }}
        run: |
          if [ -n "$BACKUP_ENCRYPTION_KEY" ]; then
            BACKUP_FILE="2fa_backup_${{ steps.date.outputs.date }}.json.gz.enc"
          else
            BACKUP_FILE="2fa_backup_${{ steps.date.outputs.date }}.json.gz"
          fi

          rclone copyto "$BACKUP_FILE" "webdav:${WEBDAV_BASE_PATH}/$BACKUP_FILE"
          echo "✅ Backup uploaded to WebDAV"

      - name: Upload to GitHub Backup Repo
        if: steps.backends.outputs.GITHUB_ENABLED == 'true'
        env:
          GH_TOKEN: ${{ secrets.GH_BACKUP_TOKEN }}
          GH_USER: ${{ secrets.GH_BACKUP_USER }}
          GH_REPO: ${{ secrets.GH_BACKUP_REPO }}
          GH_TARGET_DIR: ${{ secrets.GH_BACKUP_DIR || '2fa-backups' }}
          BACKUP_ENCRYPTION_KEY: ${{ secrets.BACKUP_ENCRYPTION_KEY }}
        run: |
          if [ -n "$BACKUP_ENCRYPTION_KEY" ]; then
            BACKUP_FILE="2fa_backup_${{ steps.date.outputs.date }}.json.gz.enc"
          else
            BACKUP_FILE="2fa_backup_${{ steps.date.outputs.date }}.json.gz"
          fi

          git clone --depth 1 "https://$GH_USER:$GH_TOKEN@github.com/$GH_USER/$GH_REPO.git" target_repo
          mkdir -p target_repo/$GH_TARGET_DIR
          cp "$BACKUP_FILE" target_repo/$GH_TARGET_DIR/
          
          cd target_repo
          git config user.name "GitHub Action Backup"
          git config user.email "action@github.com"
          git add "$GH_TARGET_DIR/$BACKUP_FILE"
          git commit -m "Backup: $BACKUP_FILE"
          git push
          echo "✅ Backup pushed to GitHub"
