name: Sync Daily Backups from KV

on:
  schedule:
    # æ¯å¤© UTC 04:00 è¿è¡Œï¼ˆåŒ—äº¬æ—¶é—´ 12:00ï¼‰
    - cron: "0 4 * * *"
  workflow_dispatch:
    inputs:
      target_date:
        description: "é€‰æ‹©è¦åŒæ­¥çš„æ—¥æœŸ (æ ¼å¼: YYYY-MM-DDï¼Œç•™ç©ºåˆ™åŒæ­¥ä»Šå¤©)"
        required: false
        default: ""

env:
  BACKUP_RETENTION_DAYS: ${{ secrets.BACKUP_RETENTION_DAYS || 30 }}
  KV_KEY_PREFIX: "backup_"

jobs:
  sync-backups:
    name: Sync Today's KV Backups
    runs-on: ubuntu-latest
    
    steps:
      - name: Check backup backends availability
        id: backends
        env:
          S3_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
          S3_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
          S3_BUCKET: ${{ secrets.S3_BUCKET }}
          S3_REGION: ${{ secrets.S3_REGION }}
          WEBDAV_URL: ${{ secrets.WEBDAV_URL }}
          WEBDAV_USER: ${{ secrets.WEBDAV_USER }}
          WEBDAV_PASSWORD: ${{ secrets.WEBDAV_PASSWORD }}
          GH_BACKUP_TOKEN: ${{ secrets.GH_BACKUP_TOKEN }}
        run: |
          # æ£€æŸ¥ S3 åŽç«¯
          if [[ -n "$S3_ACCESS_KEY_ID" && -n "$S3_SECRET_ACCESS_KEY" && -n "$S3_BUCKET" && -n "$S3_REGION" ]]; then
            echo "S3_ENABLED=true" >> $GITHUB_OUTPUT
            echo "âœ… S3 backend: enabled"
          else
            echo "S3_ENABLED=false" >> $GITHUB_OUTPUT
            echo "âš ï¸ S3 backend: disabled"
          fi
          
          # æ£€æŸ¥ WebDAV åŽç«¯
          if [[ -n "$WEBDAV_URL" && -n "$WEBDAV_USER" && -n "$WEBDAV_PASSWORD" ]]; then
            echo "WEBDAV_ENABLED=true" >> $GITHUB_OUTPUT
            echo "âœ… WebDAV backend: enabled"
          else
            echo "WEBDAV_ENABLED=false" >> $GITHUB_OUTPUT
            echo "âš ï¸ WebDAV backend: disabled"
          fi

          # æ£€æŸ¥ GitHub åŽç«¯
          if [[ -n "$GH_BACKUP_TOKEN" ]]; then
            echo "GITHUB_ENABLED=true" >> $GITHUB_OUTPUT
            echo "âœ… GitHub backend: enabled"
          else
            echo "GITHUB_ENABLED=false" >> $GITHUB_OUTPUT
            echo "âš ï¸ GitHub backend: disabled"
          fi

      - name: Get Target Date
        id: date
        run: |
          if [ -n "${{ github.event.inputs.target_date }}" ]; then
            TARGET_DATE="${{ github.event.inputs.target_date }}"
          else
            TARGET_DATE=$(date +'%Y-%m-%d')
          fi
          echo "target_date=$TARGET_DATE" >> $GITHUB_OUTPUT
          echo "ðŸŽ¯ Target Sync Date: $TARGET_DATE"

      - name: Install wrangler & jq
        run: |
          npm install -g wrangler
          sudo apt-get install -y jq

      - name: List and Fetch KV Backups
        id: fetch
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          KV_NAMESPACE_ID: ${{ secrets.KV_NAMESPACE_ID }}
        run: |
          mkdir -p sync_dir
          TARGET_DATE="${{ steps.date.outputs.target_date }}"
          
          echo "ðŸ” [DEBUG] Testing KV accessibility..."
          # å°è¯•åˆ—å‡ºæ‰€æœ‰å‘½åç©ºé—´ï¼Œçœ‹ Token æ˜¯å¦æœ‰æƒé™çœ‹åˆ°å¯¹åº”çš„ ID
          npx wrangler kv namespace list
          
          echo "ðŸ” Fetching keys from KV namespace: ${{ secrets.KV_NAMESPACE_ID }}..."
          
          # èŽ·å–æ‰€æœ‰é”®å
          RAW_OUTPUT=$(npx wrangler kv key list --namespace-id ${{ secrets.KV_NAMESPACE_ID }})
          echo "DEBUG: Raw Wrangler Output: $RAW_OUTPUT"
          
          # æ£€æŸ¥è¾“å‡ºæ˜¯å¦ä¸ºç©ºæ•°ç»„
          if [ "$RAW_OUTPUT" == "[]" ]; then
            echo "âŒ [ERROR] Cloudflare returned an empty list. This usually means the API Token lacks permissions for this specific KV Namespace."
            echo "SYNC_COUNT=0" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          COUNT=0
          for KEY in $KEYS; do
            echo "ðŸ“¥ Fetching: $KEY"
            npx wrangler kv key get "$KEY" --namespace-id ${{ secrets.KV_NAMESPACE_ID }} > "sync_dir/$KEY"
            COUNT=$((COUNT+1))
          done
          
          echo "âœ… Fetched $COUNT files."
          echo "SYNC_COUNT=$COUNT" >> $GITHUB_OUTPUT
          ls -lh sync_dir/

      - name: Setup rclone
        if: steps.backends.outputs.WEBDAV_ENABLED == 'true' && steps.fetch.outputs.SYNC_COUNT != '0'
        uses: AnimMouse/setup-rclone@v1

      - name: Configure rclone (WebDAV)
        if: steps.backends.outputs.WEBDAV_ENABLED == 'true' && steps.fetch.outputs.SYNC_COUNT != '0'
        env:
          WEBDAV_URL: ${{ secrets.WEBDAV_URL }}
          WEBDAV_VENDOR: ${{ secrets.WEBDAV_VENDOR || 'other' }}
          WEBDAV_USER: ${{ secrets.WEBDAV_USER }}
          WEBDAV_PASSWORD: ${{ secrets.WEBDAV_PASSWORD }}
        run: |
          mkdir -p ~/.config/rclone
          RCLONE_WEBDAV_PASS="$(rclone obscure "$WEBDAV_PASSWORD")"

          cat > ~/.config/rclone/rclone.conf <<EOF
          [webdav]
          type = webdav
          url = $WEBDAV_URL
          vendor = $WEBDAV_VENDOR
          user = $WEBDAV_USER
          pass = $RCLONE_WEBDAV_PASS
          EOF

      - name: Sync to Backends
        if: steps.fetch.outputs.SYNC_COUNT != '0'
        env:
          # S3 Config
          AWS_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ secrets.S3_REGION }}
          S3_BUCKET: ${{ secrets.S3_BUCKET }}
          S3_ENDPOINT: ${{ secrets.S3_ENDPOINT }}
          # WebDAV Config
          WEBDAV_BASE_PATH: ${{ secrets.WEBDAV_BASE_PATH || '2fa-backups' }}
          # GitHub Config
          GH_TOKEN: ${{ secrets.GH_BACKUP_TOKEN }}
          GH_USER: ${{ secrets.GH_BACKUP_USER }}
          GH_REPO: ${{ secrets.GH_BACKUP_REPO }}
          GH_TARGET_DIR: ${{ secrets.GH_BACKUP_DIR || '2fa-backups' }}
        run: |
          TARGET_DATE="${{ steps.date.outputs.target_date }}"
          
          # 1. Sync to S3
          if [ "${{ steps.backends.outputs.S3_ENABLED }}" == "true" ]; then
            ENDPOINT_FLAG=""
            if [ -n "$S3_ENDPOINT" ]; then
              ENDPOINT_FLAG="--endpoint-url $S3_ENDPOINT"
            fi
            echo "ðŸ“¤ Syncing to S3..."
            aws s3 sync sync_dir/ "s3://$S3_BUCKET/2fa-backups/" $ENDPOINT_FLAG
            echo "âœ… S3 sync completed."
          fi
          
          # 2. Sync to WebDAV
          if [ "${{ steps.backends.outputs.WEBDAV_ENABLED }}" == "true" ]; then
            echo "ðŸ“¤ Syncing to WebDAV..."
            rclone copy sync_dir/ "webdav:${WEBDAV_BASE_PATH}/" --verbose
            echo "âœ… WebDAV sync completed."
          fi
          
          # 3. Sync to GitHub
          if [ "${{ steps.backends.outputs.GITHUB_ENABLED }}" == "true" ]; then
            echo "ðŸ“¤ Syncing to GitHub..."
            git clone --depth 1 "https://$GH_USER:$GH_TOKEN@github.com/$GH_USER/$GH_REPO.git" target_repo
            mkdir -p "target_repo/$GH_TARGET_DIR"
            cp -r sync_dir/* "target_repo/$GH_TARGET_DIR/"
            
            cd target_repo
            git config user.name "GitHub Action Backup"
            git config user.email "action@github.com"
            git add .
            if git diff --staged --quiet; then
              echo "â„¹ï¸ No changes to commit for GitHub."
            else
              git commit -m "Backup: Sync $TARGET_DATE files"
              git push
              echo "âœ… GitHub sync completed."
            fi
          fi
